{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b981fd45-c9d8-496c-b0fe-9dccbbe284c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466ca25f-ec60-4137-9ac4-4aee7263fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/hadis/Desktop/iust\n"
     ]
    }
   ],
   "source": [
    "cd {cwd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f19ca1-612d-4efd-8137-d2efbf65ec81",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec97ca76-3d72-4545-b529-51ae6a31fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/hadi/iust/AP3D/\")\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import models\n",
    "import transforms.spatial_transforms as ST\n",
    "import tools.data_manager as data_manager\n",
    "from tools.video_loader import VideoDataset\n",
    "from tools.utils import Logger\n",
    "from tools.eval_metrics import evaluate\n",
    "from commons import modify_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Args:\n",
    "    root = \"/home/hadi/iust/datasets\"\n",
    "    dataset = \"mars\"\n",
    "    workers = 4\n",
    "    height = 256\n",
    "    width = 128\n",
    "    test_frames = 16\n",
    "    arch = \"ap3dres50\"\n",
    "    resume = \"./\"\n",
    "    pretrain = \"/home/hadi/iust/AP3D/logs/row41/best_model.pth.tar\"\n",
    "    test_epochs = [240]\n",
    "    distance = \"cosine\"\n",
    "    gpu = \"0\"\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9094fe3-7444-4f9d-91c1-83838120a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract(model, vids, use_gpu):\n",
    "    n, c, f, h, w = vids.size()\n",
    "    assert(n == 1)\n",
    "\n",
    "    if use_gpu:\n",
    "        feat = torch.cuda.FloatTensor()\n",
    "    else:\n",
    "        feat = torch.FloatTensor()\n",
    "    for i in range(math.ceil(f/args.test_frames)):\n",
    "        clip = vids[:, :, i*args.test_frames:(i+1)*args.test_frames, :, :]\n",
    "        \n",
    "        if use_gpu:\n",
    "            clip = clip.cuda()\n",
    "        output = model(clip)\n",
    "        feat = torch.cat((feat, output), 1)\n",
    "\n",
    "    feat = feat.mean(1)\n",
    "    feat = model.bn(feat)\n",
    "    feat = feat.data.cpu()\n",
    "\n",
    "    return feat\n",
    "\n",
    "\n",
    "def test(model, queryloader, galleryloader, use_gpu):\n",
    "    since = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    qf, q_pids, q_camids = [], [], []\n",
    "    print('queryloader')\n",
    "    for batch_idx, (vids, pids, camids) in tqdm(enumerate(queryloader)):\n",
    "        if (batch_idx + 1) % 1000==0:\n",
    "            print(\"{}/{}\".format(batch_idx+1, len(queryloader)))\n",
    "\n",
    "        qf.append(extract(model, vids, use_gpu).squeeze())\n",
    "        q_pids.extend(pids)\n",
    "        q_camids.extend(camids)\n",
    "\n",
    "    qf = torch.stack(qf)\n",
    "    q_pids = np.asarray(q_pids)\n",
    "    q_camids = np.asarray(q_camids)\n",
    "    print(\"Extracted features for query set, obtained {} matrix\".format(qf.shape))\n",
    "    \n",
    "    print('galleryloader')\n",
    "    gf, g_pids, g_camids = [], [], []\n",
    "    for batch_idx, (vids, pids, camids) in tqdm(enumerate(galleryloader)):\n",
    "        if (batch_idx + 1) % 1000==0:\n",
    "            print(\"{}/{}\".format(batch_idx+1, len(galleryloader)))\n",
    "\n",
    "        gf.append(extract(model, vids, use_gpu).squeeze())\n",
    "        g_pids.extend(pids)\n",
    "        g_camids.extend(camids)\n",
    "    gf = torch.stack(gf)\n",
    "    g_pids = np.asarray(g_pids)\n",
    "    g_camids = np.asarray(g_camids)\n",
    "\n",
    "    if args.dataset == 'mars':\n",
    "        # gallery set must contain query set, otherwise 140 query imgs will not have ground truth.\n",
    "        gf = torch.cat((qf, gf), 0)\n",
    "        g_pids = np.append(q_pids, g_pids)\n",
    "        g_camids = np.append(q_camids, g_camids)\n",
    "\n",
    "    print(\"Extracted features for gallery set, obtained {} matrix\".format(gf.shape))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Extracting features complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    print(\"Computing distance matrix\")\n",
    "    m, n = qf.size(0), gf.size(0)\n",
    "    distmat = torch.zeros((m,n))\n",
    "\n",
    "    if args.distance == 'euclidean':\n",
    "        distmat = torch.pow(qf, 2).sum(dim=1, keepdim=True).expand(m, n) + \\\n",
    "                  torch.pow(gf, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n",
    "        for i in range(m):\n",
    "            distmat[i:i+1].addmm_(1, -2, qf[i:i+1], gf.t())\n",
    "    else:\n",
    "        q_norm = torch.norm(qf, p=2, dim=1, keepdim=True)\n",
    "        g_norm = torch.norm(gf, p=2, dim=1, keepdim=True)\n",
    "        qf = qf.div(q_norm.expand_as(qf))\n",
    "        gf = gf.div(g_norm.expand_as(gf))\n",
    "        for i in range(m):\n",
    "            distmat[i] = - torch.mm(qf[i:i+1], gf.t())\n",
    "    distmat = distmat.numpy()\n",
    "\n",
    "    print(\"Computing CMC and mAP\")\n",
    "    cmc, mAP = evaluate(distmat, q_pids, g_pids, q_camids, g_camids)\n",
    "\n",
    "    print(\"Results ----------\")\n",
    "    print('top1:{:.1%} top5:{:.1%} top10:{:.1%} mAP:{:.1%}'.format(cmc[0],cmc[4],cmc[9],mAP))\n",
    "    print(\"------------------\")\n",
    "\n",
    "    return cmc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0dcb95-ea2b-47b5-b949-8c8a082b157f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "dataset = data_manager.init_dataset(name=args.dataset, root=args.root)\n",
    "\n",
    "spatial_transform_test = ST.Compose([\n",
    "            ST.Scale((args.height, args.width), interpolation=3),\n",
    "            ST.ToTensor(),\n",
    "            ST.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "temporal_transform_test = None\n",
    "use_gpu = torch.cuda.is_available()\n",
    "pin_memory = True if use_gpu else False\n",
    "\n",
    "queryloader = DataLoader(\n",
    "    VideoDataset(dataset.query, spatial_transform=spatial_transform_test, temporal_transform=temporal_transform_test),\n",
    "    batch_size=1, shuffle=False, num_workers=0,\n",
    "    pin_memory=pin_memory, drop_last=False)\n",
    "\n",
    "galleryloader = DataLoader(\n",
    "    VideoDataset(dataset.gallery, spatial_transform=spatial_transform_test, temporal_transform=temporal_transform_test),\n",
    "    batch_size=1, shuffle=False, num_workers=0,\n",
    "    pin_memory=pin_memory, drop_last=False)\n",
    "\n",
    "print(\"Initializing model: {}\".format(args.arch))\n",
    "model = models.init_model(name=args.arch, num_classes=dataset.num_train_pids)\n",
    "print(\"Model size: {:.5f}M\".format(sum(p.numel() for p in model.parameters())/1000000.0))\n",
    "    \n",
    "model = models.init_model(name=args.arch, num_classes=dataset.num_train_pids)\n",
    "modify_model(model, args)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test(model, queryloader, galleryloader, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0bffc-b7f0-4811-bbe5-5fe2e959826c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
