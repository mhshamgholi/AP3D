{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b981fd45-c9d8-496c-b0fe-9dccbbe284c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466ca25f-ec60-4137-9ac4-4aee7263fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shamgholi/iust/AP3D\n"
     ]
    }
   ],
   "source": [
    "cd {cwd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f19ca1-612d-4efd-8137-d2efbf65ec81",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec97ca76-3d72-4545-b529-51ae6a31fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hard/shamgholi/miniconda3/envs/reid/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(cwd)\n",
    "import time\n",
    "import math\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import models\n",
    "import transforms.spatial_transforms as ST\n",
    "import transforms.temporal_transforms as TT\n",
    "import tools.data_manager as data_manager\n",
    "from tools.video_loader import VideoDataset\n",
    "from tools.utils import Logger\n",
    "from tools.eval_metrics import evaluate\n",
    "from commons import modify_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Args:\n",
    "    #\"/home/hadi/iust/datasets\"\n",
    "    #\"/home/shamgholi/iust/datasets\" \n",
    "    root = \"/home/shamgholi/iust/datasets\" \n",
    "    dataset = \"mars\"\n",
    "    workers = 4\n",
    "    height = 256\n",
    "    width = 128\n",
    "    test_frames = 8\n",
    "    arch = \"ap3dres50\"\n",
    "    resume = \"./\"\n",
    "    pretrain = os.path.join(cwd, \"logs/row41/best_model.pth.tar\")\n",
    "    test_epochs = [240]\n",
    "    distance = \"cosine\"\n",
    "    gpu = \"0\"\n",
    "    test_batch = 4\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9094fe3-7444-4f9d-91c1-83838120a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract(model, vids, use_gpu):\n",
    "    n, c, f, h, w = vids.size()\n",
    "    assert(n == 1)\n",
    "\n",
    "    if use_gpu:\n",
    "        feat = torch.cuda.FloatTensor()\n",
    "    else:\n",
    "        feat = torch.FloatTensor()\n",
    "    for i in range(math.ceil(f/args.test_frames)):\n",
    "        clip = vids[:, :, i*args.test_frames:(i+1)*args.test_frames, :, :]\n",
    "        \n",
    "        if use_gpu:\n",
    "            clip = clip.cuda()\n",
    "        output = model(clip)\n",
    "        feat = torch.cat((feat, output), 1)\n",
    "\n",
    "    feat = feat.mean(1)\n",
    "    feat = model.bn(feat)\n",
    "    feat = feat.data.cpu()\n",
    "\n",
    "    return feat\n",
    "\n",
    "\n",
    "def test(model, queryloader, galleryloader, use_gpu):\n",
    "    # test using 4 frames\n",
    "    since = time.time()\n",
    "    model.eval()\n",
    "\n",
    "    qf, q_pids, q_camids = [], [], []\n",
    "    for batch_idx, (vids, pids, camids) in enumerate(queryloader):\n",
    "        if use_gpu:\n",
    "            vids = vids.cuda()\n",
    "        feat = model(vids)\n",
    "        feat = feat.mean(1)\n",
    "        feat = model.bn(feat)\n",
    "        feat = feat.data.cpu()\n",
    "\n",
    "        qf.append(feat)\n",
    "        q_pids.extend(pids)\n",
    "        q_camids.extend(camids)\n",
    "\n",
    "    qf = torch.cat(qf, 0)\n",
    "    q_pids = np.asarray(q_pids)\n",
    "    q_camids = np.asarray(q_camids)\n",
    "    print(\"Extracted features for query set, obtained {} matrix\".format(qf.shape))\n",
    "\n",
    "    gf, g_pids, g_camids = [], [], []\n",
    "    for batch_idx, (vids, pids, camids) in enumerate(galleryloader):\n",
    "        if use_gpu:\n",
    "            vids = vids.cuda()\n",
    "        feat = model(vids)\n",
    "        feat = feat.mean(1)\n",
    "        feat = model.bn(feat)\n",
    "        feat = feat.data.cpu()\n",
    "\n",
    "        gf.append(feat)\n",
    "        g_pids.extend(pids)\n",
    "        g_camids.extend(camids)\n",
    "\n",
    "    gf = torch.cat(gf, 0)\n",
    "    g_pids = np.asarray(g_pids)\n",
    "    g_camids = np.asarray(g_camids)\n",
    "\n",
    "    if args.dataset == 'mars':\n",
    "        # gallery set must contain query set, otherwise 140 query imgs will not have ground truth.\n",
    "        gf = torch.cat((qf, gf), 0)\n",
    "        g_pids = np.append(q_pids, g_pids)\n",
    "        g_camids = np.append(q_camids, g_camids)\n",
    "\n",
    "    print(\"Extracted features for gallery set, obtained {} matrix\".format(gf.shape))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Extracting features complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    print(\"Computing distance matrix\")\n",
    "    m, n = qf.size(0), gf.size(0)\n",
    "    distmat = torch.zeros((m,n))\n",
    "\n",
    "    if args.distance == 'euclidean':\n",
    "        distmat = torch.pow(qf, 2).sum(dim=1, keepdim=True).expand(m, n) + \\\n",
    "                  torch.pow(gf, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n",
    "        for i in range(m):\n",
    "            distmat[i:i+1].addmm_(1, -2, qf[i:i+1], gf.t())\n",
    "    else:\n",
    "        q_norm = torch.norm(qf, p=2, dim=1, keepdim=True)\n",
    "        g_norm = torch.norm(gf, p=2, dim=1, keepdim=True)\n",
    "        qf = qf.div(q_norm.expand_as(qf))\n",
    "        gf = gf.div(g_norm.expand_as(gf))\n",
    "        for i in range(m):\n",
    "            distmat[i] = - torch.mm(qf[i:i+1], gf.t())\n",
    "    distmat = distmat.numpy()\n",
    "\n",
    "    print(\"Computing CMC and mAP\")\n",
    "    cmc, mAP = evaluate(distmat, q_pids, g_pids, q_camids, g_camids)\n",
    "\n",
    "    print(\"Results ----------\")\n",
    "    print('top1:{:.1%} top5:{:.1%} top10:{:.1%} mAP:{:.1%}'.format(cmc[0],cmc[4],cmc[9],mAP))\n",
    "    print(\"------------------\")\n",
    "\n",
    "    return cmc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0dcb95-ea2b-47b5-b949-8c8a082b157f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> MARS loaded\n",
      "Dataset statistics:\n",
      "  ------------------------------\n",
      "  subset   | # ids | # tracklets\n",
      "  ------------------------------\n",
      "  train    |   625 |     8298\n",
      "  query    |   626 |     1980\n",
      "  gallery  |   622 |     9330\n",
      "  ------------------------------\n",
      "  total    |  1247 |    19608\n",
      "  number of images per tracklet: 2 ~ 920, average 59.5\n",
      "  ------------------------------\n",
      "Initializing model: ap3dres50\n",
      "Model size: 14.66388M\n",
      "pretrain state dict loaded\n",
      ">>> module conv1.weight is trainable ? False\n",
      ">>> module bn1.weight is trainable ? False\n",
      ">>> module bn1.bias is trainable ? False\n",
      ">>> module layer1.0.conv1.weight is trainable ? False\n",
      ">>> module layer1.0.bn1.weight is trainable ? False\n",
      ">>> module layer1.0.bn1.bias is trainable ? False\n",
      ">>> module layer1.0.conv2.weight is trainable ? False\n",
      ">>> module layer1.0.bn2.weight is trainable ? False\n",
      ">>> module layer1.0.bn2.bias is trainable ? False\n",
      ">>> module layer1.1.conv1.weight is trainable ? False\n",
      ">>> module layer1.1.bn1.weight is trainable ? False\n",
      ">>> module layer1.1.bn1.bias is trainable ? False\n",
      ">>> module layer1.1.conv2.weight is trainable ? False\n",
      ">>> module layer1.1.bn2.weight is trainable ? False\n",
      ">>> module layer1.1.bn2.bias is trainable ? False\n",
      ">>> module layer2.0.conv1.weight is trainable ? False\n",
      ">>> module layer2.0.bn1.weight is trainable ? False\n",
      ">>> module layer2.0.bn1.bias is trainable ? False\n",
      ">>> module layer2.0.conv2.APM.semantic_mapping.weight is trainable ? False\n",
      ">>> module layer2.0.conv2.APM.x_mapping.weight is trainable ? False\n",
      ">>> module layer2.0.conv2.APM.n_mapping.weight is trainable ? False\n",
      ">>> module layer2.0.conv2.APM.contrastive_att_net.0.weight is trainable ? False\n",
      ">>> module layer2.0.conv2.spatial_conv3d.weight is trainable ? False\n",
      ">>> module layer2.0.conv2.temporal_conv3d.weight is trainable ? False\n",
      ">>> module layer2.0.bn2.weight is trainable ? False\n",
      ">>> module layer2.0.bn2.bias is trainable ? False\n",
      ">>> module layer2.0.downsample.0.weight is trainable ? False\n",
      ">>> module layer2.0.downsample.1.weight is trainable ? False\n",
      ">>> module layer2.0.downsample.1.bias is trainable ? False\n",
      ">>> module layer2.1.conv1.weight is trainable ? False\n",
      ">>> module layer2.1.bn1.weight is trainable ? False\n",
      ">>> module layer2.1.bn1.bias is trainable ? False\n",
      ">>> module layer2.1.conv2.weight is trainable ? False\n",
      ">>> module layer2.1.bn2.weight is trainable ? False\n",
      ">>> module layer2.1.bn2.bias is trainable ? False\n",
      ">>> module layer3.0.conv1.weight is trainable ? False\n",
      ">>> module layer3.0.bn1.weight is trainable ? False\n",
      ">>> module layer3.0.bn1.bias is trainable ? False\n",
      ">>> module layer3.0.conv2.APM.semantic_mapping.weight is trainable ? False\n",
      ">>> module layer3.0.conv2.APM.x_mapping.weight is trainable ? False\n",
      ">>> module layer3.0.conv2.APM.n_mapping.weight is trainable ? False\n",
      ">>> module layer3.0.conv2.APM.contrastive_att_net.0.weight is trainable ? False\n",
      ">>> module layer3.0.conv2.spatial_conv3d.weight is trainable ? False\n",
      ">>> module layer3.0.conv2.temporal_conv3d.weight is trainable ? False\n",
      ">>> module layer3.0.bn2.weight is trainable ? False\n",
      ">>> module layer3.0.bn2.bias is trainable ? False\n",
      ">>> module layer3.0.downsample.0.weight is trainable ? False\n",
      ">>> module layer3.0.downsample.1.weight is trainable ? False\n",
      ">>> module layer3.0.downsample.1.bias is trainable ? False\n",
      ">>> module layer3.1.conv1.weight is trainable ? False\n",
      ">>> module layer3.1.bn1.weight is trainable ? False\n",
      ">>> module layer3.1.bn1.bias is trainable ? False\n",
      ">>> module layer3.1.conv2.weight is trainable ? False\n",
      ">>> module layer3.1.bn2.weight is trainable ? False\n",
      ">>> module layer3.1.bn2.bias is trainable ? False\n",
      ">>> module layer4.0.conv1.weight is trainable ? False\n",
      ">>> module layer4.0.bn1.weight is trainable ? False\n",
      ">>> module layer4.0.bn1.bias is trainable ? False\n",
      ">>> module layer4.0.conv2.weight is trainable ? False\n",
      ">>> module layer4.0.bn2.weight is trainable ? False\n",
      ">>> module layer4.0.bn2.bias is trainable ? False\n",
      ">>> module layer4.0.downsample.0.weight is trainable ? False\n",
      ">>> module layer4.0.downsample.1.weight is trainable ? False\n",
      ">>> module layer4.0.downsample.1.bias is trainable ? False\n",
      ">>> module layer4.1.conv1.weight is trainable ? False\n",
      ">>> module layer4.1.bn1.weight is trainable ? False\n",
      ">>> module layer4.1.bn1.bias is trainable ? False\n",
      ">>> module layer4.1.conv2.weight is trainable ? False\n",
      ">>> module layer4.1.bn2.weight is trainable ? False\n",
      ">>> module layer4.1.bn2.bias is trainable ? False\n",
      ">>> module hist.conv_centers.weight is trainable ? False\n",
      ">>> module hist.conv_centers.bias is trainable ? False\n",
      ">>> module hist.conv_widths.weight is trainable ? False\n",
      ">>> module hist.conv_widths.bias is trainable ? False\n",
      ">>> module feature_reduction.0.weight is trainable ? True\n",
      ">>> module feature_reduction.0.bias is trainable ? True\n",
      ">>> module bn.weight is trainable ? True\n",
      ">>> module bn.bias is trainable ? True\n",
      ">>> module classifier.weight is trainable ? True\n",
      ">>> module classifier.bias is trainable ? True\n",
      "----------\n",
      "model layers:\n",
      "ResNet503D(\n",
      "  (conv1): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=(1, 1, 1), ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck3D(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck3D(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck3D(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): APP3DC(\n",
      "        (APM): APM(\n",
      "          (padding): ConstantPad3d(padding=(0, 0, 0, 0, 1, 1), value=0)\n",
      "          (semantic_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (x_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (n_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (contrastive_att_net): Sequential(\n",
      "            (0): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (spatial_conv3d): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (temporal_conv3d): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(3, 1, 1), bias=False)\n",
      "      )\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck3D(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck3D(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): APP3DC(\n",
      "        (APM): APM(\n",
      "          (padding): ConstantPad3d(padding=(0, 0, 0, 0, 1, 1), value=0)\n",
      "          (semantic_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (x_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (n_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (contrastive_att_net): Sequential(\n",
      "            (0): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (1): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (spatial_conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (temporal_conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(3, 1, 1), bias=False)\n",
      "      )\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck3D(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck3D(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck3D(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (hist): HistYusufLayer(\n",
      "    (conv_centers): Conv2d(512, 5120, kernel_size=(1, 1), stride=(1, 1), groups=512)\n",
      "    (conv_widths): Conv2d(5120, 5120, kernel_size=(1, 1), stride=(1, 1), groups=5120)\n",
      "    (relu1): Threshold(threshold=1.0, value=0.0)\n",
      "    (gap): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (feature_reduction): Sequential(\n",
      "    (0): Linear(in_features=5632, out_features=512, bias=True)\n",
      "  )\n",
      "  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (classifier): Linear(in_features=512, out_features=625, bias=True)\n",
      ")\n",
      "Model size: 14.66388M\n",
      "Extracted features for query set, obtained torch.Size([1980, 512]) matrix\n",
      "Extracted features for gallery set, obtained torch.Size([11310, 512]) matrix\n",
      "Extracting features complete in 0m 51s\n",
      "Computing distance matrix\n",
      "Computing CMC and mAP\n",
      "Results ----------\n",
      "top1:77.9% top5:89.9% top10:92.6% mAP:64.3%\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation\n",
    "dataset = data_manager.init_dataset(name=args.dataset, root=args.root)\n",
    "\n",
    "spatial_transform_test = ST.Compose([\n",
    "            ST.Scale((args.height, args.width), interpolation=3),\n",
    "            ST.ToTensor(),\n",
    "            ST.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "temporal_transform_test = TT.TemporalBeginCrop()\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "pin_memory = True if use_gpu else False\n",
    "device = 'cuda' if use_gpu else 'cpu'\n",
    "\n",
    "queryloader = DataLoader(\n",
    "    VideoDataset(dataset.query, spatial_transform=spatial_transform_test, temporal_transform=temporal_transform_test),\n",
    "    batch_size=args.test_batch, shuffle=False, num_workers=0,\n",
    "    pin_memory=pin_memory, drop_last=False)\n",
    "\n",
    "galleryloader = DataLoader(\n",
    "    VideoDataset(dataset.gallery, spatial_transform=spatial_transform_test, temporal_transform=temporal_transform_test),\n",
    "    batch_size=args.test_batch, shuffle=False, num_workers=0,\n",
    "    pin_memory=pin_memory, drop_last=False)\n",
    "\n",
    "print(\"Initializing model: {}\".format(args.arch))\n",
    "model = models.init_model(name=args.arch, num_classes=dataset.num_train_pids)\n",
    "print(\"Model size: {:.5f}M\".format(sum(p.numel() for p in model.parameters())/1000000.0))\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "modify_model(model, args)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test(model, queryloader, galleryloader, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0bffc-b7f0-4811-bbe5-5fe2e959826c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
