==========
Args:Namespace(arch='ap3dres50', dataset='mars', distance='cosine', eval_step=10, gamma=0.1, gpu='0', height=256, lr=0.0003, margin=0.3, max_epoch=240, num_instances=4, pretrain='', resume='', root='/home/hadi/iust/datasets/', sample_stride=8, save_dir='./logs/row47', seed=1, seq_len=4, start_epoch=0, start_eval=0, stepsize=[60, 120, 180], test_batch=32, train_batch=32, use_cpu=False, weight_decay=0.0005, width=128, workers=4)
==========
Currently using CPU (GPU is highly recommended)
Initializing dataset mars
=> MARS loaded
Dataset statistics:
  ------------------------------
  subset   | # ids | # tracklets
  ------------------------------
  train    |   625 |     8298
  query    |   626 |     1980
  gallery  |   622 |     9330
  ------------------------------
  total    |  1247 |    19608
  number of images per tracklet: 2 ~ 920, average 59.5
  ------------------------------
Initializing model: ap3dres50
Model size: 13.59483M
pretrain state dict loaded
>>> module conv1.weight is trainable ? True
>>> module bn1.weight is trainable ? True
>>> module bn1.bias is trainable ? True
>>> module layer1.0.conv1.weight is trainable ? True
>>> module layer1.0.bn1.weight is trainable ? True
>>> module layer1.0.bn1.bias is trainable ? True
>>> module layer1.0.conv2.weight is trainable ? True
>>> module layer1.0.bn2.weight is trainable ? True
>>> module layer1.0.bn2.bias is trainable ? True
>>> module layer1.1.conv1.weight is trainable ? True
>>> module layer1.1.bn1.weight is trainable ? True
>>> module layer1.1.bn1.bias is trainable ? True
>>> module layer1.1.conv2.weight is trainable ? True
>>> module layer1.1.bn2.weight is trainable ? True
>>> module layer1.1.bn2.bias is trainable ? True
>>> module layer2.0.conv1.weight is trainable ? True
>>> module layer2.0.bn1.weight is trainable ? True
>>> module layer2.0.bn1.bias is trainable ? True
>>> module layer2.0.conv2.APM.semantic_mapping.weight is trainable ? True
>>> module layer2.0.conv2.APM.x_mapping.weight is trainable ? True
>>> module layer2.0.conv2.APM.n_mapping.weight is trainable ? True
>>> module layer2.0.conv2.APM.contrastive_att_net.0.weight is trainable ? True
>>> module layer2.0.conv2.spatial_conv3d.weight is trainable ? True
>>> module layer2.0.conv2.temporal_conv3d.weight is trainable ? True
>>> module layer2.0.bn2.weight is trainable ? True
>>> module layer2.0.bn2.bias is trainable ? True
>>> module layer2.0.downsample.0.weight is trainable ? True
>>> module layer2.0.downsample.1.weight is trainable ? True
>>> module layer2.0.downsample.1.bias is trainable ? True
>>> module layer2.1.conv1.weight is trainable ? True
>>> module layer2.1.bn1.weight is trainable ? True
>>> module layer2.1.bn1.bias is trainable ? True
>>> module layer2.1.conv2.weight is trainable ? True
>>> module layer2.1.bn2.weight is trainable ? True
>>> module layer2.1.bn2.bias is trainable ? True
>>> module layer3.0.conv1.weight is trainable ? True
>>> module layer3.0.bn1.weight is trainable ? True
>>> module layer3.0.bn1.bias is trainable ? True
>>> module layer3.0.conv2.APM.semantic_mapping.weight is trainable ? True
>>> module layer3.0.conv2.APM.x_mapping.weight is trainable ? True
>>> module layer3.0.conv2.APM.n_mapping.weight is trainable ? True
>>> module layer3.0.conv2.APM.contrastive_att_net.0.weight is trainable ? True
>>> module layer3.0.conv2.spatial_conv3d.weight is trainable ? True
>>> module layer3.0.conv2.temporal_conv3d.weight is trainable ? True
>>> module layer3.0.bn2.weight is trainable ? True
>>> module layer3.0.bn2.bias is trainable ? True
>>> module layer3.0.downsample.0.weight is trainable ? True
>>> module layer3.0.downsample.1.weight is trainable ? True
>>> module layer3.0.downsample.1.bias is trainable ? True
>>> module layer3.1.conv1.weight is trainable ? True
>>> module layer3.1.bn1.weight is trainable ? True
>>> module layer3.1.bn1.bias is trainable ? True
>>> module layer3.1.conv2.weight is trainable ? True
>>> module layer3.1.bn2.weight is trainable ? True
>>> module layer3.1.bn2.bias is trainable ? True
>>> module layer4.0.conv1.weight is trainable ? True
>>> module layer4.0.bn1.weight is trainable ? True
>>> module layer4.0.bn1.bias is trainable ? True
>>> module layer4.0.conv2.weight is trainable ? True
>>> module layer4.0.bn2.weight is trainable ? True
>>> module layer4.0.bn2.bias is trainable ? True
>>> module layer4.0.downsample.0.weight is trainable ? True
>>> module layer4.0.downsample.1.weight is trainable ? True
>>> module layer4.0.downsample.1.bias is trainable ? True
>>> module layer4.1.conv1.weight is trainable ? True
>>> module layer4.1.bn1.weight is trainable ? True
>>> module layer4.1.bn1.bias is trainable ? True
>>> module layer4.1.conv2.weight is trainable ? True
>>> module layer4.1.bn2.weight is trainable ? True
>>> module layer4.1.bn2.bias is trainable ? True
>>> module hist.hist_edges is trainable ? False
>>> module bn.weight is trainable ? True
>>> module bn.bias is trainable ? True
>>> module classifier.weight is trainable ? True
>>> module classifier.bias is trainable ? True
>>> module feature_reduction.0.weight is trainable ? True
>>> module feature_reduction.0.bias is trainable ? True
----------
model layers:
ResNet503D(
  (conv1): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=(1, 1, 1), ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck3D(
      (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): Bottleneck3D(
      (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck3D(
      (conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): APP3DC(
        (APM): APM(
          (padding): ConstantPad3d(padding=(0, 0, 0, 0, 1, 1), value=0)
          (semantic_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (x_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (n_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (contrastive_att_net): Sequential(
            (0): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): Sigmoid()
          )
        )
        (spatial_conv3d): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (temporal_conv3d): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(3, 1, 1), bias=False)
      )
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck3D(
      (conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck3D(
      (conv1): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): APP3DC(
        (APM): APM(
          (padding): ConstantPad3d(padding=(0, 0, 0, 0, 1, 1), value=0)
          (semantic_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (x_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (n_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (contrastive_att_net): Sequential(
            (0): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): Sigmoid()
          )
        )
        (spatial_conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (temporal_conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(3, 1, 1), bias=False)
      )
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck3D(
      (conv1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck3D(
      (conv1): Conv3d(256, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck3D(
      (conv1): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (hist): HistByProf()
  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (classifier): Linear(in_features=512, out_features=625, bias=True)
  (feature_reduction): Sequential(
    (0): Linear(in_features=3584, out_features=512, bias=True)
  )
)
Model size: 13.59483M
==> Start training
