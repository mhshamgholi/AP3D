==========
Args:Namespace(arch='ap3dres50', dataset='mars', distance='hist_intersection', eval_step=10, gamma=0.1, gpu='0', height=256, lr=0.0003, margin=0.3, max_epoch=240, num_instances=4, pretrain='./logs/row41/best_model.pth.tar', resume='', root='/home/shamgholi/iust/datasets/', sample_stride=8, save_dir='./logs/row54', seed=1, seq_len=4, start_epoch=0, start_eval=0, stepsize=[60, 120, 180], test_batch=32, train_batch=32, use_cpu=False, weight_decay=0.0005, width=128, workers=4)
==========
Currently using GPU 0
Initializing dataset mars
=> MARS loaded
Dataset statistics:
  ------------------------------
  subset   | # ids | # tracklets
  ------------------------------
  train    |   625 |     8298
  query    |   626 |     1980
  gallery  |   622 |     9330
  ------------------------------
  total    |  1247 |    19608
  number of images per tracklet: 2 ~ 920, average 59.5
  ------------------------------
Initializing model: ap3dres50
Model size: 13.37671M
--------------------
RUNTIMEERROR IN LOADING BATCHNORM STATEDICT, WEIGHTS OF BN IS NOW RANDOM
--------------------
pretrain state dict loaded
>>> module conv1.weight is trainable ? False
>>> module bn1.weight is trainable ? False
>>> module bn1.bias is trainable ? False
>>> module layer1.0.conv1.weight is trainable ? False
>>> module layer1.0.bn1.weight is trainable ? False
>>> module layer1.0.bn1.bias is trainable ? False
>>> module layer1.0.conv2.weight is trainable ? False
>>> module layer1.0.bn2.weight is trainable ? False
>>> module layer1.0.bn2.bias is trainable ? False
>>> module layer1.1.conv1.weight is trainable ? False
>>> module layer1.1.bn1.weight is trainable ? False
>>> module layer1.1.bn1.bias is trainable ? False
>>> module layer1.1.conv2.weight is trainable ? False
>>> module layer1.1.bn2.weight is trainable ? False
>>> module layer1.1.bn2.bias is trainable ? False
>>> module layer2.0.conv1.weight is trainable ? False
>>> module layer2.0.bn1.weight is trainable ? False
>>> module layer2.0.bn1.bias is trainable ? False
>>> module layer2.0.conv2.APM.semantic_mapping.weight is trainable ? False
>>> module layer2.0.conv2.APM.x_mapping.weight is trainable ? False
>>> module layer2.0.conv2.APM.n_mapping.weight is trainable ? False
>>> module layer2.0.conv2.APM.contrastive_att_net.0.weight is trainable ? False
>>> module layer2.0.conv2.spatial_conv3d.weight is trainable ? False
>>> module layer2.0.conv2.temporal_conv3d.weight is trainable ? False
>>> module layer2.0.bn2.weight is trainable ? False
>>> module layer2.0.bn2.bias is trainable ? False
>>> module layer2.0.downsample.0.weight is trainable ? False
>>> module layer2.0.downsample.1.weight is trainable ? False
>>> module layer2.0.downsample.1.bias is trainable ? False
>>> module layer2.1.conv1.weight is trainable ? False
>>> module layer2.1.bn1.weight is trainable ? False
>>> module layer2.1.bn1.bias is trainable ? False
>>> module layer2.1.conv2.weight is trainable ? False
>>> module layer2.1.bn2.weight is trainable ? False
>>> module layer2.1.bn2.bias is trainable ? False
>>> module layer3.0.conv1.weight is trainable ? False
>>> module layer3.0.bn1.weight is trainable ? False
>>> module layer3.0.bn1.bias is trainable ? False
>>> module layer3.0.conv2.APM.semantic_mapping.weight is trainable ? False
>>> module layer3.0.conv2.APM.x_mapping.weight is trainable ? False
>>> module layer3.0.conv2.APM.n_mapping.weight is trainable ? False
>>> module layer3.0.conv2.APM.contrastive_att_net.0.weight is trainable ? False
>>> module layer3.0.conv2.spatial_conv3d.weight is trainable ? False
>>> module layer3.0.conv2.temporal_conv3d.weight is trainable ? False
>>> module layer3.0.bn2.weight is trainable ? False
>>> module layer3.0.bn2.bias is trainable ? False
>>> module layer3.0.downsample.0.weight is trainable ? False
>>> module layer3.0.downsample.1.weight is trainable ? False
>>> module layer3.0.downsample.1.bias is trainable ? False
>>> module layer3.1.conv1.weight is trainable ? False
>>> module layer3.1.bn1.weight is trainable ? False
>>> module layer3.1.bn1.bias is trainable ? False
>>> module layer3.1.conv2.weight is trainable ? False
>>> module layer3.1.bn2.weight is trainable ? False
>>> module layer3.1.bn2.bias is trainable ? False
>>> module layer4.0.conv1.weight is trainable ? False
>>> module layer4.0.bn1.weight is trainable ? False
>>> module layer4.0.bn1.bias is trainable ? False
>>> module layer4.0.conv2.weight is trainable ? False
>>> module layer4.0.bn2.weight is trainable ? False
>>> module layer4.0.bn2.bias is trainable ? False
>>> module layer4.0.downsample.0.weight is trainable ? False
>>> module layer4.0.downsample.1.weight is trainable ? False
>>> module layer4.0.downsample.1.bias is trainable ? False
>>> module layer4.1.conv1.weight is trainable ? False
>>> module layer4.1.bn1.weight is trainable ? False
>>> module layer4.1.bn1.bias is trainable ? False
>>> module layer4.1.conv2.weight is trainable ? False
>>> module layer4.1.bn2.weight is trainable ? False
>>> module layer4.1.bn2.bias is trainable ? False
>>> module hist.conv_centers.weight is trainable ? False
>>> module hist.conv_centers.bias is trainable ? False
>>> module hist.conv_widths.weight is trainable ? False
>>> module hist.conv_widths.bias is trainable ? False
>>> module bn.weight is trainable ? True
>>> module bn.bias is trainable ? True
>>> module classifier.weight is trainable ? True
>>> module classifier.bias is trainable ? True
----------
model layers:
ResNet503D(
  (conv1): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=(1, 1, 1), ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck3D(
      (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): Bottleneck3D(
      (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck3D(
      (conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): APP3DC(
        (APM): APM(
          (padding): ConstantPad3d(padding=(0, 0, 0, 0, 1, 1), value=0)
          (semantic_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (x_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (n_mapping): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (contrastive_att_net): Sequential(
            (0): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): Sigmoid()
          )
        )
        (spatial_conv3d): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (temporal_conv3d): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(3, 1, 1), bias=False)
      )
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck3D(
      (conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck3D(
      (conv1): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): APP3DC(
        (APM): APM(
          (padding): ConstantPad3d(padding=(0, 0, 0, 0, 1, 1), value=0)
          (semantic_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (x_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (n_mapping): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (contrastive_att_net): Sequential(
            (0): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (1): Sigmoid()
          )
        )
        (spatial_conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
        (temporal_conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(3, 1, 1), bias=False)
      )
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck3D(
      (conv1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck3D(
      (conv1): Conv3d(256, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck3D(
      (conv1): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (hist): HistYusufLayer(
    (conv_centers): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), groups=512)
    (conv_widths): Conv2d(3072, 3072, kernel_size=(1, 1), stride=(1, 1), groups=3072)
    (relu1): Threshold(threshold=1.0, value=0.0)
    (gap): AdaptiveAvgPool2d(output_size=1)
  )
  (bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (classifier): Linear(in_features=3072, out_features=625, bias=True)
)
Model size: 13.37671M
